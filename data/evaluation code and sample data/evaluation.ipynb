{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JtQ_dZW0gfdD"},"source":["# Evaluate Theme Clasification and Summarization\r\n","\r\n","1. **Theme classification**: Precision, Recall and F1 Score \r\n","2. **Entity based sentiment**: Accuracy of Brand identification and Precision, Recall and F1 Score Sentiment \r\n","3. **Automated Headlines evaluation**: (*Note: The generated Headlines need to be in English irrespective of the language in the article*)\r\n","Average similarity scores of AI generated headlines compared with actual headlines would be used as a metric for evaluation.\r\n","4. **Rough and BLEU score**: To evaluate the language summarization."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEiMbOVsPSDX","executionInfo":{"status":"ok","timestamp":1614701192644,"user_tz":-330,"elapsed":1121,"user":{"displayName":"Akash Rawat","photoUrl":"","userId":"05064438118558107156"}},"outputId":"6e8a570c-dfd9-4aa6-d4d6-d531dee3462d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZpfuQHhnfCL","executionInfo":{"status":"ok","timestamp":1614701192648,"user_tz":-330,"elapsed":1117,"user":{"displayName":"Akash Rawat","photoUrl":"","userId":"05064438118558107156"}},"outputId":"148d83dd-4ad6-409e-91da-d9dba5e13521"},"source":["import os \r\n","\r\n","# the base Google Drive directory\r\n","root_dir = \"/content/drive/My Drive/\"\r\n","\r\n","# choose where you want your project files to be saved\r\n","project_folder = \"Colab Notebooks/Text Summarization and classification/\"\r\n","\r\n","def create_and_set_working_directory(project_folder):\r\n","  # check if your project folder exists. if not, it will be created.\r\n","  if os.path.isdir(root_dir + project_folder) == False:\r\n","    os.mkdir(root_dir + project_folder)\r\n","    print(root_dir + project_folder + ' did not exist but was created.')\r\n","\r\n","  # change the OS to use your project folder as the working directory\r\n","  os.chdir(root_dir + project_folder)\r\n","\r\n","  # create a test file to make sure it shows up in the right place\r\n","  #!touch 'new_file_in_working_directory.txt'\r\n","  print('\\nYour working directory was changed to ' + root_dir + project_folder)\r\n","\r\n","create_and_set_working_directory(project_folder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Your working directory was changed to /content/drive/My Drive/Colab Notebooks/Text Summarization and classification/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5LeVq589mJk","executionInfo":{"status":"ok","timestamp":1614701201326,"user_tz":-330,"elapsed":9789,"user":{"displayName":"Akash Rawat","photoUrl":"","userId":"05064438118558107156"}},"outputId":"5eb72b71-7440-4173-d0a1-3708cff9b0bc"},"source":["!pip install -U sentence-transformers\r\n","!pip install -U rouge\r\n","!pip install fuzzywuzzy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.7/dist-packages (0.4.1.2)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.1+cu101)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.3.3)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.7.0)\n","Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.1)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n","Requirement already up-to-date: rouge in /usr/local/lib/python3.7/dist-packages (1.0.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n","Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (0.18.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JPIrUh0pZQTz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614701201327,"user_tz":-330,"elapsed":9785,"user":{"displayName":"Akash Rawat","photoUrl":"","userId":"05064438118558107156"}},"outputId":"32cb37e4-9cc1-434f-e48d-e0f4b132b6ae"},"source":["# Import libraries\r\n","import scipy\r\n","import pandas as pd\r\n","from sentence_transformers import SentenceTransformer\r\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n","from sklearn.metrics import classification_report\r\n","from rouge import Rouge\r\n","from statistics import mean\r\n","from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\r\n","from fuzzywuzzy import fuzz\r\n","import nltk\r\n","nltk.download('punkt')\r\n","import warnings\r\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-6JroNatp8FK"},"source":["## Read Data"]},{"cell_type":"code","metadata":{"id":"XePPoI0pO6nH"},"source":["# Reading the data\r\n","output1_df = pd.read_csv(\"Output Data/sample_output_1.csv\")\r\n","output2_df = pd.read_csv(\"Output Data/sample_output_2.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTB3abIj0uWc"},"source":["# Data subsetting\r\n","\r\n","# Articles\r\n","count_article_df = output1_df[output1_df['Text_ID'].astype(str).str.contains('article', case=False, regex=True)]\r\n","df1 = count_article_df['Mobile_Tech_Flag_Actual'].value_counts()\r\n","article_mobile_tech, article_others = df1[1], df1[0]\r\n","\r\n","# Tweets\r\n","count_tweet_df = output1_df[output1_df['Text_ID'].astype(str).str.contains('tweet', case=False, regex=True)]\r\n","df2 = count_tweet_df['Mobile_Tech_Flag_Actual'].value_counts()\r\n","tweet_mobile_tech, tweet_others = df2[1], df2[0]\r\n","\r\n","# Articles and Tweets with mobile tech\r\n","mobile_tech_count_df = pd.DataFrame(columns=['Mobile_Tech', 'Others'])\r\n","mobile_tech_count_df.loc['Articles',:] = [article_mobile_tech,article_others]\r\n","mobile_tech_count_df.loc['Tweets',:] = [tweet_mobile_tech,tweet_others]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l4-SS-IRqBA9"},"source":["## Theme Classification Metrices"]},{"cell_type":"code","metadata":{"id":"IKOcHCIxVJG_"},"source":["# Overall\r\n","# Theme classification Actual and Predicted labels\r\n","y_mobiletech_true = output1_df['Mobile_Tech_Flag_Actual'].values\r\n","y_mobiletech_pred = output1_df['Mobile_Tech_Flag_Predicted'].values\r\n","\r\n","# Get scores for Theme classification\r\n","precision = round(precision_score(y_mobiletech_true, y_mobiletech_pred),2)\r\n","recall = round(recall_score(y_mobiletech_true, y_mobiletech_pred),2)\r\n","f_score = round(f1_score(y_mobiletech_true, y_mobiletech_pred),2)\r\n","acc_score = round(accuracy_score(y_mobiletech_true, y_mobiletech_pred),2)\r\n","\r\n","# Article\r\n","# Theme classification Actual and Predicted labels\r\n","article1_df = output1_df[output1_df['Text_ID'].astype(str).str.contains('article', case=False, regex=True)]\r\n","article1_mobiletech_true = article1_df['Mobile_Tech_Flag_Actual'].values\r\n","article1_mobiletech_pred = article1_df['Mobile_Tech_Flag_Predicted'].values\r\n","\r\n","# Get scores for Theme classification\r\n","article_precision = round(precision_score(article1_mobiletech_true, article1_mobiletech_pred),2)\r\n","article_recall = round(recall_score(article1_mobiletech_true, article1_mobiletech_pred),2)\r\n","article_f_score = round(f1_score(article1_mobiletech_true, article1_mobiletech_pred),2)\r\n","article_acc_score = round(accuracy_score(article1_mobiletech_true, article1_mobiletech_pred),2)\r\n","\r\n","# Tweets\r\n","# Theme classification Actual and Predicted labels\r\n","tweet1_df = output1_df[output1_df['Text_ID'].astype(str).str.contains('tweet', case=False, regex=True)]\r\n","tweet_mobiletech_true = tweet1_df['Mobile_Tech_Flag_Actual'].values\r\n","tweet_mobiletech_pred = tweet1_df['Mobile_Tech_Flag_Predicted'].values\r\n","\r\n","# Get scores for Theme classification\r\n","tweet_precision = round(precision_score(tweet_mobiletech_true, tweet_mobiletech_pred),2)\r\n","tweet_recall = round(recall_score(tweet_mobiletech_true, tweet_mobiletech_pred),2)\r\n","tweet_f_score = round(f1_score(tweet_mobiletech_true, tweet_mobiletech_pred),2)\r\n","tweet_acc_score = round(accuracy_score(tweet_mobiletech_true, tweet_mobiletech_pred),2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FT9ksS0SpkOZ"},"source":["## Calculate Headline Similarity\r\n","  - Actual Headline\r\n","  - Generated Headline in Original Language"]},{"cell_type":"code","metadata":{"id":"dCQA88JpZUli"},"source":["# Headlines Actual and Predicted\r\n","headline_df = output1_df[~output1_df['Headline_Actual_Eng'].isna()]\r\n","y_headlines_true = headline_df['Headline_Actual_Eng']\r\n","y_headlines_pred = headline_df['Headline_Generated_Eng_Lang']\r\n","\r\n","# Get average document similarity using BERT\r\n","model = SentenceTransformer('bert-base-nli-mean-tokens')\r\n","\r\n","headline_similarity = []\r\n","for actual_headline, predicted_headline in zip(y_headlines_true, y_headlines_pred):\r\n","  actual_headline_embeddings = model.encode(actual_headline) # Get a vector for each headlines\r\n","  predicted_headline_embeddings = model.encode(predicted_headline) # Get a vector for each headlines\r\n","  distance = scipy.spatial.distance.cdist([actual_headline_embeddings], [predicted_headline_embeddings], \"cosine\")[0]\r\n","  headline_similarity.append(\"%.4f\" % (1-distance))\r\n","\r\n","headline_similarity = list(map(float, headline_similarity))\r\n","avg_headline_sim_score = round(mean(headline_similarity),2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qq-WZzMHpP3r"},"source":["## Calculate Rouge Scores for text summarization"]},{"cell_type":"code","metadata":{"id":"8md6PVMIiITh"},"source":["rouge = Rouge()\r\n","\r\n","# Headlines Actual and Predicted\r\n","headline_df = output1_df[~output1_df['Headline_Actual_Eng'].isna()]\r\n","y_headlines_true = headline_df['Headline_Actual_Eng']\r\n","y_headlines_pred = headline_df['Headline_Generated_Eng_Lang']\r\n","\r\n","rouge_scores = []\r\n","for actual_headline, predicted_headline in zip(y_headlines_true, y_headlines_pred):\r\n","  rouge_score = rouge.get_scores(actual_headline, predicted_headline)\r\n","  rouge_scores.append(rouge_score[0]['rouge-l'])\r\n","\r\n","# Averaging the scores\r\n","f = [score['f'] for score in rouge_scores]\r\n","p = [score['p'] for score in rouge_scores]\r\n","r = [score['r'] for score in rouge_scores]\r\n","\r\n","avg_rogue_scores = {'F1 Score':round(mean(f),2),\r\n","                    'Precision':round(mean(p),2),\r\n","                    'Recall':round(mean(r),2)}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwLDBYcnpJUM"},"source":["## Calculate BLEU Scores for text summarization"]},{"cell_type":"code","metadata":{"id":"uGIKNc99iTH_"},"source":["headline_df = output1_df[~output1_df['Headline_Actual_Eng'].isna()]\r\n","\r\n","org_headlines = headline_df['Headline_Actual_Eng'] # summarized texts\r\n","gen_headlines = headline_df['Headline_Generated_Eng_Lang'] # summarized texts\r\n","\r\n","bleu_scores = []\r\n","for org_headline, gen_headline in zip(org_headlines, gen_headlines):\r\n","  hypothesis = gen_headline.split()\r\n","  reference = org_headline.split()\r\n","  references = [reference] # list of references for 1 sentence.\r\n","  list_of_references = [references] # list of references for all sentences in corpus.\r\n","  list_of_hypotheses = [hypothesis] # list of hypotheses that corresponds to list of references.\r\n","  bleu_score = corpus_bleu(list_of_references, list_of_hypotheses)\r\n","  bleu_scores.append(bleu_score)\r\n","\r\n","avg_bleu_scores = round(mean(bleu_scores),2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ugjAPrlSpXZR"},"source":["## Evaluate Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"DBzmsUhJeG9p"},"source":["def map_sentiments(sentiment):\r\n","  '''\r\n","  Map sentiment tags to labels\r\n","    - negative : 0\r\n","    - positive : 1      \r\n","    - neutral : 2\r\n","  '''\r\n","  sentiment = sentiment.lower()\r\n","  if sentiment == 'positive':\r\n","    return 1\r\n","  elif sentiment == 'negative':\r\n","    return 0\r\n","  else:\r\n","    return 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rf93hFGo9bu_"},"source":["# Brand Similarity and Sentiment Score Evaluation"]},{"cell_type":"code","metadata":{"id":"vIWHJ2zCVs-a"},"source":["# fuzzy matching for Brands\r\n","sentiment_df = output2_df[~(output2_df['Brands_Entity_Actual'].isna() & output2_df['Brands_Entity_Identified'].isna())]\r\n","\r\n","def compute_sim(text, my_list, threshold):\r\n","  #score_list = [(fuzz.ratio(text, x), x) for x in my_list]\r\n","  score_list = [(1, x) for x in my_list if fuzz.ratio(text, x)>threshold]\r\n","  # print(score_list)\r\n","  if score_list:\r\n","    return 1, str(score_list[0][1])\r\n","  else:\r\n","    return 0, \"\"\r\n","\r\n","final_df = pd.DataFrame()\r\n","for id in sentiment_df['Text_ID'].unique():\r\n","  temp_df = output2_df.loc[output2_df['Text_ID'] == id, ].reset_index(drop=True)\r\n","\r\n","  actual_list, predict_list = list(temp_df['Brands_Entity_Actual'].unique()), list(temp_df['Brands_Entity_Identified'].unique())\r\n","\r\n","  temp_df_actual = temp_df[['Text_ID','Brands_Entity_Actual','Sentiment_Actual']].drop_duplicates()\r\n","  temp_df_predict = temp_df[['Text_ID','Brands_Entity_Identified','Sentiment_Identified']].drop_duplicates(subset=['Text_ID','Brands_Entity_Identified'])\r\n","\r\n","  temp_df_actual = temp_df_actual.reset_index(drop=True)\r\n","  temp_df_predict = temp_df_predict.reset_index(drop=True)\r\n","\r\n","  temp_df_actual['Actual_Brand'], temp_df_predict['Prediction_Brand'] = 0,0\r\n","  temp_df_actual['Actual_Sent'], temp_df_predict['Prediction_Sent'] = 0,0\r\n","\r\n","  for i in range(temp_df_actual.shape[0]):\r\n","    temp_df_actual.loc[i,'Actual_Brand'], match_text = compute_sim(temp_df_actual.loc[i, 'Brands_Entity_Actual'], my_list=predict_list, threshold=0.7)\r\n","    if temp_df_actual.loc[i,'Actual_Brand'] == 1:\r\n","      df_A = temp_df_predict.loc[temp_df_predict['Brands_Entity_Identified'] == match_text,'Sentiment_Identified'].reset_index(drop=True)\r\n","      temp_df_actual.loc[i,'Actual_Sent'] = bool(temp_df_actual.loc[i,'Sentiment_Actual'] == df_A[0])\r\n","\r\n","  for i in range(temp_df_predict.shape[0]):\r\n","    temp_df_predict.loc[i,'Prediction_Brand'], match_text = compute_sim(str(temp_df_predict.loc[i, 'Brands_Entity_Identified']), actual_list, threshold=0.7)\r\n","    if temp_df_predict.loc[i,'Prediction_Brand'] == 1:\r\n","      df_B = temp_df_actual.loc[temp_df_actual['Brands_Entity_Actual'] == match_text,'Sentiment_Actual'].reset_index(drop=True)\r\n","      temp_df_predict.loc[i,'Prediction_Sent'] = bool(temp_df_predict.loc[i,'Sentiment_Identified'] == df_B[0])\r\n","\r\n","  temp_df1 = pd.DataFrame({'Text_ID': id,\r\n","                           'Recall_Brand': round(temp_df_actual['Actual_Brand'].sum()/(len(temp_df_actual)),2),\r\n","                           'Precision_Brand': round(temp_df_predict['Prediction_Brand'].sum()/len(temp_df_predict),2),\r\n","                           'Recall_Sent': round(temp_df_actual['Actual_Sent'].sum()/(len(temp_df_actual)),2),\r\n","                           'Precision_Sent': round(temp_df_predict['Prediction_Sent'].sum()/len(temp_df_predict),2)}, index=[0])\r\n","\r\n","  final_df = final_df.append(temp_df1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgF5TsfNWjIP"},"source":["# Text Sentiment Scores\r\n","# Overall\r\n","overall_sent_precision = round(final_df['Precision_Sent'].mean(),2)\r\n","overall_sent_recall = round(final_df['Recall_Sent'].mean(),2)\r\n","\r\n","# article\r\n","article2_df = final_df[final_df['Text_ID'].astype(str).str.contains('article', case=False, regex=True)]\r\n","article_sent_precision = round(article2_df['Precision_Sent'].mean(),2)\r\n","article_sent_recall = round(article2_df['Recall_Sent'].mean(),2)\r\n","\r\n","# tweets\r\n","tweet2_df = final_df[final_df['Text_ID'].astype(str).str.contains('tweet', case=False, regex=True)]\r\n","tweet_sent_precision = round(tweet2_df['Precision_Sent'].mean(),2)\r\n","tweet_sent_recall = round(tweet2_df['Recall_Sent'].mean(),2)\r\n","\r\n","# Brand Prediction Scores\r\n","# Overall\r\n","overall_brand_precision = round(final_df['Precision_Brand'].mean(),2)\r\n","overall_brand_recall = round(final_df['Recall_Brand'].mean(),2)\r\n","\r\n","# article\r\n","article2_df = final_df[final_df['Text_ID'].astype(str).str.contains('article', case=False, regex=True)]\r\n","article_brand_precision = round(article2_df['Precision_Brand'].mean(),2)\r\n","article_brand_recall = round(article2_df['Recall_Brand'].mean(),2)\r\n","\r\n","# tweets\r\n","tweet2_df = final_df[final_df['Text_ID'].astype(str).str.contains('tweet', case=False, regex=True)]\r\n","tweet_brand_precision = round(tweet2_df['Precision_Brand'].mean(),2)\r\n","tweet_brand_recall = round(tweet2_df['Recall_Brand'].mean(),2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9t4xmNrKpcVB"},"source":["## Generate Evaluation Report"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UmZWtZrWKnpG","executionInfo":{"status":"ok","timestamp":1614701206311,"user_tz":-330,"elapsed":14729,"user":{"displayName":"Akash Rawat","photoUrl":"","userId":"05064438118558107156"}},"outputId":"eab43e9c-5596-47fa-e790-4f3794b36401"},"source":["print(\"**  Data Overview **\")\r\n","print(mobile_tech_count_df)\r\n","\r\n","print(\"=\"*30, \"Article\", \"=\"*30)\r\n","print(\"1. Theme classification evaluation (for mobile tech):\")\r\n","print('> Precision : {}%'.format(round(article_precision*100,2)))\r\n","print(f'> Recall : {article_recall*100}%')\r\n","print(f'> F1 Score: {article_f_score*100}%')\r\n","print(f'> Accuracy Score: {acc_score*100}%')\r\n","print('-'*5)\r\n","print(\"2. Entity based evaluation\")\r\n","print(\"Brand Identification:\")\r\n","print(f'> Precision : {article_brand_precision*100}%')\r\n","print(f'> Recall : {article_brand_recall*100}%')\r\n","print('-'*5)\r\n","print(\"Sentiment Analysis:\")\r\n","print(f'> Precision : {article_sent_precision*100}%')\r\n","print(f'> Recall : {article_sent_recall*100}%')\r\n","print('-'*5)\r\n","print('3. Automated Headlines evaluation')\r\n","print(f'--> Average similarity scores: {avg_headline_sim_score*100}%')\r\n","print(\"--> Rough Score:\")\r\n","for k,v in avg_rogue_scores.items():\r\n","  print('\\t> {} : {}%'.format(k, round(v*100,2)))\r\n","print(f'--> BLEU Score: {avg_bleu_scores*100}%')\r\n","print('-'*70)\r\n","#----------------------------------------------------------------\r\n","print(\"=\"*30, \"Tweet\", \"=\"*30)\r\n","print(\"1. Theme classification evaluation (for mobile tech):\")\r\n","print(f'> Precision : {tweet_precision*100}%')\r\n","print(f'> Recall : {tweet_recall*100}%')\r\n","print(f'> F1 Score: {tweet_f_score*100}%')\r\n","print('-'*5)\r\n","print(\"2. Entity based evaluation\")\r\n","print(\"Brand Identification:\")\r\n","print(f'> Precision : {tweet_brand_precision*100}%')\r\n","print(f'> Recall : {tweet_brand_recall*100}%')\r\n","print('-'*5)\r\n","print(\"Sentiment Analysis:\")\r\n","print(f'> Precision : {tweet_sent_precision*100}%')\r\n","print(f'> Recall : {tweet_sent_recall*100}%')\r\n","print('-'*70)\r\n","#----------------------------------------------------------------\r\n","print(\"=\"*30, \"Overall\", \"=\"*30)\r\n","print(\"1. Theme classification evaluation (for mobile tech):\")\r\n","print(f'> Precision : {precision*100}%')\r\n","print(f'> Recall : {recall*100}%')\r\n","print(f'> F1 Score: {f_score*100}%')\r\n","print(f'> Accuracy Score: {acc_score*100}%')\r\n","print('-'*5)\r\n","print(\"2. Entity based evaluation\")\r\n","print(\"Brand Identification:\")\r\n","print(f'> Precision : {overall_brand_precision*100}%')\r\n","print(f'> Recall : {overall_brand_recall*100}%')\r\n","print('-'*5)\r\n","print(\"Sentiment Analysis:\")\r\n","print(f'> Precision : {overall_sent_precision*100}%')\r\n","print(f'> Recall : {overall_sent_recall*100}%')\r\n","print('3. Automated Headlines evaluation')\r\n","print(f'--> Average similarity scores: {avg_headline_sim_score*100}%')\r\n","print(\"--> Rough Score:\")\r\n","for k,v in avg_rogue_scores.items():\r\n","  print('\\t> {} : {}%'.format(k, round(v*100,2)))  \r\n","print(f'--> BLEU Score : {avg_bleu_scores*100}%')\r\n","print('-'*70)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["**  Data Overview **\n","         Mobile_Tech Others\n","Articles           8      7\n","Tweets            14      1\n","============================== Article ==============================\n","1. Theme classification evaluation (for mobile tech):\n","> Precision : 57.0%\n","> Recall : 50.0%\n","> F1 Score: 53.0%\n","> Accuracy Score: 60.0%\n","-----\n","2. Entity based evaluation\n","Brand Identification:\n","> Precision : 67.0%\n","> Recall : 100.0%\n","-----\n","Sentiment Analysis:\n","> Precision : 33.0%\n","> Recall : 0.0%\n","-----\n","3. Automated Headlines evaluation\n","--> Average similarity scores: 66.0%\n","--> Rough Score:\n","\t> F1 Score : 33.0%\n","\t> Precision : 29.0%\n","\t> Recall : 42.0%\n","--> BLEU Score: 32.0%\n","----------------------------------------------------------------------\n","============================== Tweet ==============================\n","1. Theme classification evaluation (for mobile tech):\n","> Precision : 100.0%\n","> Recall : 64.0%\n","> F1 Score: 78.0%\n","-----\n","2. Entity based evaluation\n","Brand Identification:\n","> Precision : 100.0%\n","> Recall : 100.0%\n","-----\n","Sentiment Analysis:\n","> Precision : 75.0%\n","> Recall : 75.0%\n","----------------------------------------------------------------------\n","============================== Overall ==============================\n","1. Theme classification evaluation (for mobile tech):\n","> Precision : 81.0%\n","> Recall : 59.0%\n","> F1 Score: 68.0%\n","> Accuracy Score: 60.0%\n","-----\n","2. Entity based evaluation\n","Brand Identification:\n","> Precision : 97.0%\n","> Recall : 100.0%\n","-----\n","Sentiment Analysis:\n","> Precision : 71.0%\n","> Recall : 68.0%\n","3. Automated Headlines evaluation\n","--> Average similarity scores: 66.0%\n","--> Rough Score:\n","\t> F1 Score : 33.0%\n","\t> Precision : 29.0%\n","\t> Recall : 42.0%\n","--> BLEU Score : 32.0%\n","----------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f7omWxWBjIpH"},"source":[""],"execution_count":null,"outputs":[]}]}